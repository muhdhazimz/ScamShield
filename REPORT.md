# Scam Message Classification: Report

## Data Preprocessing

### 1. Data Cleaning:
- **URL Removal**: URLs are removed because they generally do not contribute meaningfully to text classification. 
- **Non-Alphabetic Characters**: These are removed to ensure the model doesn’t misinterpret special symbols or numbers and emojis that are often included in text messages that don't add value to scam detection.
- **Lowercasing & Space Stripping**: These standardization steps help variations in text formatting do not affect the classification.

### 2. No Stopword Removal or Lemmatization:
DistilBERT  handles stopwords and lemmatization through its tokenization process, preserving the contextual meaning of words. Removing stopwords or lemmatization would likely be redundant.

### 3. Imbalance Handling:
Undersampling was applied to balance the dataset by reducing the number of legitimate samples to match the scam class. This is to avoid biases.

### 4. Dataset Splitting

The **80-16-4** split (80% training, 16% validation, 4% testing) was chosen to balance model performance.

## Model Selection

### DistilBERT
- Traditional methods like SVM, Decision Trees, or Random Forests typically struggle with capturing the complexity and context of text data. These models rely heavily on feature engineering, which would require manually identifying important scam-related terms. In contrast, DistilBERT automatically learns these features from raw text and understands the entire context of a sentence without relying to other features. This allows it to better capture the patterns of scam messages.
- While prompt-based classification (like using LLM) could work, it requires more computational resources and might be excessive for this task. 

## Training and Hyperparameters

### 1. Number of Epochs
The model was trained for 10 epochs initially, during which the performance improved steadily. However, by the 6th epoch, training loss began to stabilize, indicating that the model was close to optimal.
Round 2 was conducted with hyperparameters adjustment using 5 epochs to fine-tune the model further. This shorter period allowed it to refine its weights without overfitting.

### 2. Batch Size
A batch size of 16 was selected for efficient training. With a large dataset, this size provides a balance between training speed and model performance. 

## Model Evaluation
The model achieved the following performance on the test set:

| Metric     | Scam | Legitimate | Accuracy |
|------------|------|------------|----------|
| Precision  | 0.97 | 0.98       | 0.98     |
| Recall     | 0.98 | 0.98       | 0.98     |
| F1-Score   | 0.98 | 0.98       | 0.98     |

## ScamShield App Objectives
This solution directly supports ScamShield's objectives by providing a platform to block scam SMS messages. The model identifies scam messages, and later on can flag them, and can be used to alert users. The classifier’s ability to differentiate between legitimate and scam messages ensures that users are warned and protected from fraudulent activities. Furthermore, it can help report scam senders by tagging the message as potentially fraudulent.

## Future Work

### Subcategory Classification:
Future steps could involve using prompt-based classification to categorize scams into subtypes, such as phishing, investment fraud, or lottery scams. This would provide users not only with a scam classification but also a detailed justification generated by the LLM.

### Extended Attack Pattern Detection:
To further improve security, models could be trained to detect other forms such as embedded code.
